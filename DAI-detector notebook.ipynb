{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation:\n",
    "\n",
    "### Tech stack:\n",
    "    1. I use Open CV for working with images and video\n",
    "    2. I use Image AI as YOLO v3 framework for object detection\n",
    "        GitHub: https://github.com/OlafenwaMoses/ImageAI/\n",
    "    3. I use openpyxl for writing Excel files\n",
    "    4. I use PyQT as User Interface\n",
    "    5. Deploy via py2exe\n",
    "    \n",
    "### Deployment environment:\n",
    "As packet manager I use Anaconda. Firstly create an environment:\n",
    "    <pre><code>\n",
    "    conda create -n DAI-detector -c anaconda keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0 jupyter\n",
    "    </code></pre>\n",
    "Next import Tensorflow:\n",
    "    <pre><code>\n",
    "    pip install tensorflow==2.4.0\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install tensorflow-gpu==2.4.0\n",
    "    </code></pre>\n",
    "Check for updates:\n",
    "    <pre><code>\n",
    "    pip install imageai --upgrade\n",
    "    </code></pre>\n",
    "Now install libraries:\n",
    "    <pre><code>\n",
    "    pip install pandas\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install openpyxl\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install xlswriter\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install pyqt5\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install pyqt5-tools\n",
    "    </code></pre>\n",
    "    <pre><code>\n",
    "    pip install py2exe\n",
    "    </code></pre>\n",
    "    \n",
    "    \n",
    "## Annotating Data:\n",
    "I use the labelImg annotation tool:\n",
    "https://github.com/tzutalin/labelImg#hotkeys\n",
    "\n",
    "### First cascade detect classes below:\n",
    "- DAI - the workspace of DAI\n",
    "\n",
    "### Second cascade detect classes below:\n",
    "\n",
    "- cMCH - the center of the micron clock hand\n",
    "- eMCH - the edge of the micron clock hand\n",
    "- mmWS - mm clock face workzone\n",
    "- mmCH - mm clock hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First version of DAI (distance amplifying instrument) Detector\n",
    "\n",
    "### Initialize the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "import numpy as np\n",
    "import requests as req\n",
    "import os as os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "This section need if you want to train your own detection model. If you don't, skip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training part (first cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"res/first cascade\")\n",
    "\n",
    "trainer.setTrainConfig(object_names_array=[\"DAI\"], batch_size=4, num_experiments=10, \n",
    "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
    "\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training part (Second cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"res/second cascade\")\n",
    "\n",
    "trainer.setTrainConfig(object_names_array=[\"cMCH\", \"MCH\", \"mmWS\", \"mmCH\"], batch_size=4, num_experiments=20, \n",
    "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
    "\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video slice\n",
    "\n",
    "Pretty useful script for slicing video into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def videoSlice(inputFile, outputFolder, step = 2):\n",
    "    if os.path.exists(inputFile) and os.path.exists(outputFolder):\n",
    "        current_data = time.strftime(\"%d%m%y %H%M%S\", time.localtime())\n",
    "        cap = cv.VideoCapture(inputFile)\n",
    "        i = 0\n",
    "        while (cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            for a in range(step-1):\n",
    "                ret, frame = cap.read()  \n",
    "            if type(frame) != type(np.array([])):\n",
    "                print(\"broken frame\")\n",
    "                break\n",
    "            \n",
    "            cropPath = \"{0}/{1} {2}.png\".format(outputFolder, current_data, i)\n",
    "            cv.imwrite(cropPath, frame)\n",
    "            display('proccesed: {0}'.format(i))\n",
    "            i += 1\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        display('Done')\n",
    "    else:\n",
    "        return 'no such a file'\n",
    "\n",
    "videoSlice(\"INPUT/FILE\", \"OUTPUT/FILE\", step = 5) #Step means use every 1 of $step$ image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web-Cam Test\n",
    "\n",
    "If you dont sure that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "cap.set(3, 640)  # width size\n",
    "cap.set(4, 480)  # height size\n",
    "while True:\n",
    "    succes, img = cap.read();\n",
    "    if succes:\n",
    "        cv.imshow(\"Video\", img)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        print(\"Access denied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the programme starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math/Geometry functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientation(x1, x2, x3, y1, y2, y3): # Orientation of point x3,y3 relative to vector starts in x1,y1 and ends in x2,y2\n",
    "    x3 -= x1\n",
    "    y3 -= y1\n",
    "    a = ((x2 - x1)**2 + (y2- y1)**2)**0.5\n",
    "    b = x2 - x1\n",
    "    c = y2 - y1\n",
    "    if b == 0 or c == 0:\n",
    "        return 0\n",
    "    alpha = (b*b + c*c - a*a)/(2*b*c)    \n",
    "    M = np.array([[alpha, -np.sin(np.arccos(alpha))], [np.sin(np.arccos(alpha)), alpha]]) # Transformation matrix Oxy -> vector's basis    \n",
    "    #X3 = M[0,0] * x3 + M[0,1] * y3\n",
    "    Y3 = M[1,0] * x3 + M[1,1] * y3    \n",
    "    if Y3 > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def cosTh(x3, x2, x1, y3, y2, y1): # Angle between vectors c = (x3 - x1, y3 - y1) and b = (x3 - x2, y3 - y2)\n",
    "    a = ((x2 - x1)**2 + (y2- y1)**2)**0.5\n",
    "    b = ((x3 - x1)**2 + (y3- y1)**2)**0.5\n",
    "    c = ((x3 - x2)**2 + (y3- y2)**2)**0.5\n",
    "    \n",
    "    if b == 0 or c == 0:\n",
    "        return 0\n",
    "    alpha = (b*b + c*c - a*a)/(2*b*c)\n",
    "    if orientation(x1, x3, x2, y1, y3, y2):\n",
    "        alpha = 180 - np.arccos(alpha)*180/np.pi\n",
    "    else:\n",
    "        alpha = 180 + np.arccos(alpha)*180/np.pi\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def scale(x, y, w, h, scaleKoef = 0.1):\n",
    "    hh = round(scaleKoef * (h - y))\n",
    "    ww = round(scaleKoef * (w - x))\n",
    "    if y - hh > 0 and x - ww > 0:\n",
    "        y -= hh\n",
    "        x -= ww\n",
    "        h += hh\n",
    "        w += ww\n",
    "    return x, y, w, h\n",
    "\n",
    "def drawLine(image, x1, x2, y1, y2, koef = 2.5, line_thickness = 2, approx = 0):\n",
    "    cv.line(image, (x2, y2), (x1, y1), (0, 255, 0), thickness=line_thickness)\n",
    "    if approx:\n",
    "        dX = x2 - x1\n",
    "        dY = y2 - y1\n",
    "        dX = round(x1 - dX * koef)\n",
    "        dY = round(y1 - dY * koef)\n",
    "        cv.line(image, (dX, dY), (x1, y1), (0, 0, 255), thickness=line_thickness)\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "\n",
    "class DAIdetector:\n",
    "    \n",
    "    def __init__(self, fstProb = 50, secProb = 50):\n",
    "        self.fstProb = fstProb\n",
    "        self.secProb = secProb\n",
    "        \n",
    "        self.detector = CustomObjectDetection()\n",
    "        self.detector.setModelTypeAsYOLOv3()\n",
    "        self.detector.setModelPath(\"res/first cascade/models/detection_model-ex-015--loss-0013.902.h5\") #Model file\n",
    "        self.detector.setJsonPath(\"res/first cascade/json/detection_config.json\") #Its JSON file\n",
    "        self.detector.loadModel()\n",
    "\n",
    "        self.AngleDetector = CustomObjectDetection()\n",
    "        self.AngleDetector.setModelTypeAsYOLOv3()\n",
    "        self.AngleDetector.setModelPath(\"res/second cascade/models/detection_model-ex-015--loss-0022.383.h5\") #Model file\n",
    "        self.AngleDetector.setJsonPath(\"res/second cascade/json/detection_config.json\") #Its JSON file\n",
    "        self.AngleDetector.loadModel()\n",
    "        pass\n",
    "    \n",
    "    def detectDAI(self, inputImg, inputType = \"file\"):       \n",
    "        inputImg = inputImg.copy()\n",
    "        detectedImage, detections = self.detector.detectObjectsFromImage(output_type=\"array\", input_type = inputType,\n",
    "                                                                         input_image = inputImg, \n",
    "                                                                         minimum_percentage_probability = self.fstProb)\n",
    "        DAI, DAIcoord, alpha, DAIimgSet = np.array([]), np.array([]), np.array([]), []\n",
    "    \n",
    "        i = 0\n",
    "           \n",
    "        for eachDAI in detections:\n",
    "            if eachDAI[\"name\"] == \"DAI\":\n",
    "                eachDAI[\"name\"] = \"DAI {0}\".format(i)\n",
    "                x,y,w,h = eachDAI[\"box_points\"]\n",
    "                #x,y,w,h = scale(x,y,w,h)\n",
    "                cropImg = inputImg[y : h, x : w] \n",
    "                cropImg = cv.resize(cropImg, (320, 320))\n",
    "                \n",
    "                current_time = time.strftime(\"%d%m%y %H%M%S\", time.localtime())\n",
    "                cropPath = \"res/buffer/SecCasImg/{0} {1}.jpg\".format(current_time, i)\n",
    "                cv.imwrite(cropPath, cropImg)\n",
    "            \n",
    "                Angles, detAngles = self.AngleDetector.detectObjectsFromImage(output_type='array', input_type = 'array',\n",
    "                                                                              input_image = cropImg,\n",
    "                                                                              minimum_percentage_probability = self.secProb)\n",
    "                procIMG, a = self.secondCascade(cropImg, detAngles)\n",
    "                if a == None:\n",
    "                    a = 'Can not detect'\n",
    "                    procIMG = Angles\n",
    "                DAI = np.append(DAI, eachDAI[\"name\"])\n",
    "                DAIcoord = np.append(DAIcoord, eachDAI[\"box_points\"])\n",
    "                alpha = np.append(alpha, a)\n",
    "                DAIimgSet.append(procIMG) \n",
    "                i += 1\n",
    "\n",
    "        return detectedImage, DAI, DAIcoord, alpha, DAIimgSet\n",
    "\n",
    "    def secondCascade(self, Angles, detAngles):\n",
    "        x1, x2, x3, x4, y1, y2, y3, y4 = -1,-1,-1,-1,-1,-1,-1,-1\n",
    "        cMCH, MCH, mmWS, mmCH = 0,0,0,0\n",
    "        for el in detAngles:\n",
    "            if el['name'] == 'cMCH' and el['percentage_probability'] > cMCH:\n",
    "                cMCH = el['percentage_probability']\n",
    "                x1, y1, a, b = el['box_points']\n",
    "                x1, y1 = round((x1 + a)/2), round((y1 + b)/2)\n",
    "            elif el['name'] == 'MCH'and el['percentage_probability'] > MCH:\n",
    "                MCH = el['percentage_probability']\n",
    "                x2, y2, a, b = el['box_points']\n",
    "                x2, y2 = round((x2 + a)/2), round((y2 + b)/2)\n",
    "            elif el['name'] == 'mmWS'and el['percentage_probability'] > mmWS:\n",
    "                mmWS = el['percentage_probability']\n",
    "                x3, y3, a, b = el['box_points']\n",
    "                x3, y3 = round((x3 + a)/2), round((y3 + b)/2)\n",
    "            elif el['name'] == 'mmCH'and el['percentage_probability'] > mmCH:\n",
    "                mmCH = el['percentage_probability']\n",
    "                x4, y4, a, b = el['box_points']\n",
    "                x4, y4 = round((x4 + a)/2), round((y4 + b)/2)\n",
    "        if x1 == -1 or x2 == -1 or x3 == -1:\n",
    "            return Angles, None\n",
    "            \n",
    "        drawLine(Angles, x1, x2, y1, y2, approx = 1)\n",
    "        micronAngle = cosTh(x1, x2, x3, y1, y2, y3)\n",
    "        \n",
    "        org = (6, 15)\n",
    "        fontScale = 0.4\n",
    "        thickness = 1\n",
    "        \n",
    "        micronAngle = round(micronAngle / 180 * 50) #angle to microns\n",
    "        if micronAngle == 100:\n",
    "            micronAngle = 0\n",
    "        if x4 != -1:\n",
    "            drawLine(Angles, x3, x4, y3, y4)\n",
    "            mmAngle = cosTh(x3, x4, x1, y3, y4, y1)\n",
    "            if micronAngle < 50 and (mmAngle - math.floor(mmAngle) >= 20):\n",
    "                mmAngle = math.ceil(mmAngle / 180 * 5) #angle to mm\n",
    "            else:\n",
    "                mmAngle = round(mmAngle / 180 * 5) #angle to mm\n",
    "            if mmAngle >= 10 or mmAngle <= 0:\n",
    "                mmAngle = 0\n",
    "            image = cv.putText(Angles, 'a= {0} mm'.format(round(mmAngle + micronAngle/100, 2)), org, cv.FONT_HERSHEY_SIMPLEX, \n",
    "                           fontScale, (0,0,255), thickness, cv.LINE_AA)\n",
    "            return image, mmAngle + micronAngle/100\n",
    "        else:\n",
    "            if micronAngle >= 10:\n",
    "                image = cv.putText(Angles, 'a=?.{0} mm'.format(micronAngle), org, cv.FONT_HERSHEY_SIMPLEX, \n",
    "                           fontScale, (0,0,255), thickness, cv.LINE_AA)\n",
    "                return image, '?.{0}'.format(micronAngle)\n",
    "            else:\n",
    "                image = cv.putText(Angles, 'a=?.0{0} mm'.format(micronAngle), org, cv.FONT_HERSHEY_SIMPLEX, \n",
    "                           fontScale, (0,0,255), thickness, cv.LINE_AA)\n",
    "                return image, '?.0{0}'.format(micronAngle)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl \n",
    "\n",
    "class ExcelPrinter:\n",
    "    \n",
    "    def __init__(self, directory = \"res/output\", fileName = \"DAI\"):\n",
    "        self.directory = directory\n",
    "        self.fileName = fileName\n",
    "        self.data = pd.DataFrame({'Data': [], 'Time': [], 'DAI' : [], 'DAI coordinates: x' : [],\n",
    "                                'DAI coordinates: y' : [], 'DAI coordinates: w' : [], 'DAI coordinates: h' : [],\n",
    "                                'Angle' : []})\n",
    "        pass\n",
    "    \n",
    "    def addObservation(self, DAI, DAIcoord, angles): \n",
    "        t = time.localtime()\n",
    "        current_time = time.strftime(\"%X\", t)\n",
    "        current_data = time.strftime(\"%x\", t)\n",
    "        for i in range(len(DAI)):\n",
    "            name = DAI[i]\n",
    "            a = angles[i]\n",
    "            x = DAIcoord[4 * i]\n",
    "            y = DAIcoord[4 * i + 1]\n",
    "            w = DAIcoord[4 * i + 2]\n",
    "            h = DAIcoord[4 * i + 3]\n",
    "            new_row = {'Data': current_data,'Time': current_time, 'DAI' : name, 'DAI coordinates: x' : x,\n",
    "                        'DAI coordinates: y' : y, 'DAI coordinates: w' : w, 'DAI coordinates: h' : h, 'Angle' : a}\n",
    "            self.data = self.data.append(new_row, ignore_index=True)\n",
    "        with pd.ExcelWriter(\"{0}/{1}.xlsx\".format(self.directory, self.fileName), mode=\"w\", engine='openpyxl') as writer:\n",
    "            self.data.to_excel(writer, sheet_name=\"DAI\")\n",
    "            \n",
    "        \n",
    "    def newfile(self):\n",
    "        with pd.ExcelWriter(\"{0}/DAI.xlsx\".format(self.directory), engine='xlsxwriter') as writer:\n",
    "            self.data.to_excel(writer, sheet_name='DAI')\n",
    "            writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QFileDialog, QApplication, QWidget, QLabel, QMessageBox\n",
    "from PyQt5.QtGui import QImage, QIcon, QPixmap\n",
    "\n",
    "import cv2 as cv\n",
    "import time \n",
    "\n",
    "class Ui_MainWindow(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fstProbability = 50 # First cascade probability value\n",
    "        self.secProbability = 50 # Second cascade probability value\n",
    "        self.detectionModel = DAIdetector(fstProb = self.fstProbability, secProb = self.secProbability)\n",
    "        self.outputResolution = (500,500)\n",
    "        self.workStatus = False\n",
    "        self.saveFolder = 'res/output'\n",
    "        self.imgStream = None\n",
    "        self.fileName = None # Will hold the image address location\n",
    "        self.origTmp = None # Original image\n",
    "        self.procTmp = None # Proccesed image\n",
    "        self.camPort = 0 # Camera port\n",
    "        pass\n",
    "    \n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.setObjectName(\"MainWindow\")\n",
    "        MainWindow.resize(800, 600)\n",
    "        MainWindow.setMinimumSize(QtCore.QSize(800, 600))\n",
    "        MainWindow.setMaximumSize(QtCore.QSize(800, 600))\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    "        self.centralwidget.setObjectName(\"centralwidget\")\n",
    "        self.verticalLayoutWidget = QtWidgets.QWidget(self.centralwidget)\n",
    "        self.verticalLayoutWidget.setGeometry(QtCore.QRect(0, 0, 631, 541))\n",
    "        self.verticalLayoutWidget.setObjectName(\"verticalLayoutWidget\")\n",
    "        self.showStack = QtWidgets.QVBoxLayout(self.verticalLayoutWidget)\n",
    "        self.showStack.setContentsMargins(0, 0, 0, 0)\n",
    "        self.showStack.setObjectName(\"showStack\")\n",
    "        self.ImageOutputTabs = QtWidgets.QTabWidget(self.verticalLayoutWidget)\n",
    "        self.ImageOutputTabs.setObjectName(\"ImageOutputTabs\")\n",
    "        self.origTab = QtWidgets.QWidget()\n",
    "        self.origTab.setMinimumSize(QtCore.QSize(500, 500))\n",
    "        self.origTab.setObjectName(\"origTab\")\n",
    "        self.origImg = QtWidgets.QLabel(self.origTab)\n",
    "        self.origImg.setGeometry(QtCore.QRect(0, 0, 500, 500))\n",
    "        self.origImg.setFrameShape(QtWidgets.QFrame.Box)\n",
    "        self.origImg.setFrameShadow(QtWidgets.QFrame.Plain)\n",
    "        self.origImg.setText(\"\")\n",
    "        self.origImg.setObjectName(\"origImg\")\n",
    "        self.ImageOutputTabs.addTab(self.origTab, \"\")\n",
    "        self.procTab = QtWidgets.QWidget()\n",
    "        self.procTab.setObjectName(\"procTab\")\n",
    "        self.procImg = QtWidgets.QLabel(self.procTab)\n",
    "        self.procImg.setGeometry(QtCore.QRect(0, 0, 500, 500))\n",
    "        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Maximum)\n",
    "        sizePolicy.setHorizontalStretch(0)\n",
    "        sizePolicy.setVerticalStretch(0)\n",
    "        sizePolicy.setHeightForWidth(self.procImg.sizePolicy().hasHeightForWidth())\n",
    "        self.procImg.setSizePolicy(sizePolicy)\n",
    "        self.procImg.setFrameShape(QtWidgets.QFrame.Box)\n",
    "        self.procImg.setFrameShadow(QtWidgets.QFrame.Plain)\n",
    "        self.procImg.setText(\"\")\n",
    "        self.procImg.setTextFormat(QtCore.Qt.AutoText)\n",
    "        self.procImg.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.procImg.setWordWrap(False)\n",
    "        self.procImg.setObjectName(\"procImg\")\n",
    "        self.ImageOutputTabs.addTab(self.procTab, \"\")\n",
    "        self.showStack.addWidget(self.ImageOutputTabs)\n",
    "        self.InputStreamTabs = QtWidgets.QTabWidget(self.centralwidget)\n",
    "        self.InputStreamTabs.setGeometry(QtCore.QRect(640, 179, 160, 301))\n",
    "        self.InputStreamTabs.setObjectName(\"InputStreamTabs\")\n",
    "        self.file = QtWidgets.QWidget()\n",
    "        self.file.setObjectName(\"file\")\n",
    "        self.fileImputButton = QtWidgets.QPushButton(self.file)\n",
    "        self.fileImputButton.setGeometry(QtCore.QRect(0, 10, 150, 28))\n",
    "        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Minimum)\n",
    "        sizePolicy.setHorizontalStretch(0)\n",
    "        sizePolicy.setVerticalStretch(0)\n",
    "        sizePolicy.setHeightForWidth(self.fileImputButton.sizePolicy().hasHeightForWidth())\n",
    "        self.fileImputButton.setSizePolicy(sizePolicy)\n",
    "        self.fileImputButton.setObjectName(\"fileImputButton\")\n",
    "        self.InputStreamTabs.addTab(self.file, \"\")\n",
    "        self.cam = QtWidgets.QWidget()\n",
    "        self.cam.setObjectName(\"cam\")\n",
    "        self.cameraPort = QtWidgets.QComboBox(self.cam)\n",
    "        self.cameraPort.setGeometry(QtCore.QRect(10, 10, 130, 22))\n",
    "        self.cameraPort.setObjectName(\"cameraPort\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.cameraPort.addItem(\"\")\n",
    "        self.InputStreamTabs.addTab(self.cam, \"\")\n",
    "        self.Text = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.Text.setGeometry(QtCore.QRect(640, 0, 160, 40))\n",
    "        font = QtGui.QFont()\n",
    "        font.setFamily(\"Times New Roman\")\n",
    "        font.setPointSize(12)\n",
    "        self.Text.setFont(font)\n",
    "        self.Text.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.Text.setObjectName(\"Text\")\n",
    "        self.probabilitySliderFirst = QtWidgets.QSlider(self.centralwidget)\n",
    "        self.probabilitySliderFirst.setGeometry(QtCore.QRect(640, 60, 151, 22))\n",
    "        self.probabilitySliderFirst.setMinimum(1)\n",
    "        self.probabilitySliderFirst.setProperty(\"value\", 50)\n",
    "        self.probabilitySliderFirst.setOrientation(QtCore.Qt.Horizontal)\n",
    "        self.probabilitySliderFirst.setObjectName(\"probabilitySliderFirst\")\n",
    "        self.startButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.startButton.setGeometry(QtCore.QRect(640, 480, 160, 30))\n",
    "        self.startButton.setObjectName(\"startButton\")\n",
    "        self.stopButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.stopButton.setGeometry(QtCore.QRect(640, 510, 160, 30))\n",
    "        self.stopButton.setObjectName(\"stopButton\")\n",
    "        self.fileOutputButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.fileOutputButton.setGeometry(QtCore.QRect(640, 140, 150, 28))\n",
    "        self.fileOutputButton.setObjectName(\"fileOutputButton\")\n",
    "        self.probabilitySliderSecond = QtWidgets.QSlider(self.centralwidget)\n",
    "        self.probabilitySliderSecond.setGeometry(QtCore.QRect(640, 110, 151, 22))\n",
    "        self.probabilitySliderSecond.setMinimum(1)\n",
    "        self.probabilitySliderSecond.setProperty(\"value\", 50)\n",
    "        self.probabilitySliderSecond.setOrientation(QtCore.Qt.Horizontal)\n",
    "        self.probabilitySliderSecond.setObjectName(\"probabilitySliderSecond\")\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label.setGeometry(QtCore.QRect(640, 40, 150, 16))\n",
    "        self.label.setObjectName(\"label\")\n",
    "        self.label_2 = QtWidgets.QLabel(self.centralwidget)\n",
    "        self.label_2.setGeometry(QtCore.QRect(640, 90, 141, 16))\n",
    "        self.label_2.setObjectName(\"label_2\")\n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.menubar = QtWidgets.QMenuBar(MainWindow)\n",
    "        self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 26))\n",
    "        self.menubar.setObjectName(\"menubar\")\n",
    "        MainWindow.setMenuBar(self.menubar)\n",
    "        self.statusbar = QtWidgets.QStatusBar(MainWindow)\n",
    "        self.statusbar.setObjectName(\"statusbar\")\n",
    "        MainWindow.setStatusBar(self.statusbar)\n",
    "\n",
    "        self.retranslateUi(MainWindow)\n",
    "        self.ImageOutputTabs.setCurrentIndex(0)\n",
    "        self.InputStreamTabs.setCurrentIndex(1)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "        \n",
    "        self.add_functions()\n",
    "        self.reset()\n",
    "\n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"DAI detector\"))\n",
    "        self.ImageOutputTabs.setTabText(self.ImageOutputTabs.indexOf(self.origTab), _translate(\"MainWindow\", \"Original Image\"))\n",
    "        self.ImageOutputTabs.setTabText(self.ImageOutputTabs.indexOf(self.procTab), _translate(\"MainWindow\", \"Proccesed Image\"))\n",
    "        self.fileImputButton.setText(_translate(\"MainWindow\", \"Input File\"))\n",
    "        self.InputStreamTabs.setTabText(self.InputStreamTabs.indexOf(self.file), _translate(\"MainWindow\", \"File\"))\n",
    "        self.cameraPort.setItemText(0, _translate(\"MainWindow\", \"1\"))\n",
    "        self.cameraPort.setItemText(1, _translate(\"MainWindow\", \"2\"))\n",
    "        self.cameraPort.setItemText(2, _translate(\"MainWindow\", \"3\"))\n",
    "        self.cameraPort.setItemText(3, _translate(\"MainWindow\", \"4\"))\n",
    "        self.cameraPort.setItemText(4, _translate(\"MainWindow\", \"5\"))\n",
    "        self.cameraPort.setItemText(5, _translate(\"MainWindow\", \"6\"))\n",
    "        self.cameraPort.setItemText(6, _translate(\"MainWindow\", \"7\"))\n",
    "        self.cameraPort.setItemText(7, _translate(\"MainWindow\", \"8\"))\n",
    "        self.cameraPort.setItemText(8, _translate(\"MainWindow\", \"9\"))\n",
    "        self.cameraPort.setItemText(9, _translate(\"MainWindow\", \"10\"))\n",
    "        self.InputStreamTabs.setTabText(self.InputStreamTabs.indexOf(self.cam), _translate(\"MainWindow\", \"Camera\"))\n",
    "        self.Text.setText(_translate(\"MainWindow\", \"Min % probability\"))\n",
    "        self.startButton.setText(_translate(\"MainWindow\", \"START\"))\n",
    "        self.stopButton.setText(_translate(\"MainWindow\", \"STOP\"))\n",
    "        self.fileOutputButton.setText(_translate(\"MainWindow\", \"Output File\"))\n",
    "        self.label.setText(_translate(\"MainWindow\", \"First cascade: 50\"))\n",
    "        self.label_2.setText(_translate(\"MainWindow\", \"Second cascade: 50\"))\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.fstProbability = 50 # First cascade probability value\n",
    "        self.secProbability = 50 # Second cascade probability value\n",
    "        self.detectionModel = DAIdetector(fstProb = self.fstProbability, secProb = self.secProbability)\n",
    "        self.outputResolution = (500,500)\n",
    "        self.workStatus = False\n",
    "        self.saveFolder = 'res/output'\n",
    "        self.imgStream = None\n",
    "        self.fileName = None # Will hold the image address location\n",
    "        self.origTmp = None # Original image\n",
    "        self.procTmp = None # Proccesed image\n",
    "        self.camPort = 0 # Camera port\n",
    "    \n",
    "    def add_functions(self):\n",
    "        self.startButton.clicked.connect(self.start)\n",
    "        self.stopButton.clicked.connect(self.stop)\n",
    "        self.fileImputButton.clicked.connect(self.loadVideo)\n",
    "        self.fileOutputButton.clicked.connect(self.setSaveFolder)\n",
    "        self.probabilitySliderFirst.valueChanged['int'].connect(self.firstProbValue)\n",
    "        self.probabilitySliderSecond.valueChanged['int'].connect(self.secondProbValue)\n",
    "        \n",
    "    def erMessage(self, winName, erText):\n",
    "        msg = QMessageBox()\n",
    "        msg.setWindowTitle(winName)\n",
    "        msg.setText(erText)\n",
    "        msg.setIcon(QMessageBox.Warning)\n",
    "        msg.setStandardButtons(QMessageBox.Ok)\n",
    "        msg.exec_()\n",
    "        \n",
    "    def start(self):   \n",
    "        output = ExcelPrinter(directory = self.saveFolder)\n",
    "        output.newfile()\n",
    "        frame_num = 0\n",
    "        start_time = time.time()\n",
    "        fps = 0\n",
    "        self.workStatus = True\n",
    "        try:\n",
    "            fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "            vidout = cv.VideoWriter('{0}/{1}.mp4'.format(self.saveFolder, 'Proccesed video'),\n",
    "                                    fourcc, 20.0, (500, 500))\n",
    "\n",
    "            er = 0\n",
    "            while (self.imgStream.isOpened()):  \n",
    "                ret, frame = self.imgStream.read()  \n",
    "                if type(frame) != type(np.array([])):\n",
    "                    if er > 3:\n",
    "                        break\n",
    "                    er += 1\n",
    "                    print(\"broken frame\")\n",
    "                    continue\n",
    "\n",
    "                image, DAI, DAIcoord, alpha, DAIimgSet = self.detectionModel.detectDAI(frame, inputType = \"array\")\n",
    "\n",
    "                end_time = time.time()\n",
    "                fps = fps * 0.9 + 1/(end_time - start_time) * 0.1\n",
    "                start_time = end_time\n",
    "                # Draw additional info\n",
    "                image = cv.resize(image, (500,500))\n",
    "                frame_info = 'Frame: {0}, FPS: {1:.2f}'.format(frame_num, fps)\n",
    "                cv.putText(image, frame_info, (10, image.shape[0]-10),\n",
    "                            cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "                outImage = self.multiStack(DAIimgSet)\n",
    "                self.setOrigFrame(image)\n",
    "                self.setProcFrame(outImage)\n",
    "\n",
    "                print(DAI, DAIcoord, alpha)\n",
    "                if len(DAIcoord) != 0:\n",
    "                    output.addObservation(DAI, DAIcoord, alpha)\n",
    "                vidout.write(cv.flip(cv.flip(outImage,0), 0))\n",
    "\n",
    "                key = cv.waitKey(1) & 0xFF\n",
    "\n",
    "                # Exit\n",
    "                if not self.workStatus:\n",
    "                    break\n",
    "\n",
    "                # Take screenshot\n",
    "                if key == ord('s'):\n",
    "                    cv.imwrite('{0}/frame_{1}.jpg'.format(self.saveFolder, time.time()), frame)\n",
    "\n",
    "                frame_num += 1\n",
    "            display('Done')\n",
    "        except BaseException:\n",
    "            self.erMessage('Error', str(BaseException))\n",
    "        else:\n",
    "            self.erMessage('working status', 'Computations complete')\n",
    "        finally:\n",
    "            self.workStatus = False\n",
    "            self.imgStream.release()\n",
    "            vidout.release()\n",
    "    \n",
    "    def stop(self):\n",
    "        self.workStatus = False\n",
    "        pass\n",
    "        \n",
    "    def loadVideo(self):\n",
    "        file = QFileDialog.getOpenFileName(filter=\"Video (*.*)\")[0]\n",
    "        if not os.path.exists(file):\n",
    "            raise IOError('Can\\'t open \"{0}\"'.format(file))\n",
    "        self.imgStream = cv.VideoCapture(file)\n",
    "        fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "        #self.video = cv.imread(self.fileName)\n",
    "        print('File choosen: {0}'.format(file))\n",
    "        self.update()\n",
    "\n",
    "    def setOrigFrame(self,image):\n",
    "        self.origTmp = image\n",
    "        image = cv.resize(image, (500, 500))\n",
    "        frame = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image = QImage(frame, frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)\n",
    "        self.origImg.setPixmap(QtGui.QPixmap.fromImage(image))\n",
    "\n",
    "    def setProcFrame(self,image):\n",
    "        self.procTmp = image\n",
    "        image = cv.resize(image, (500, 500))\n",
    "        frame = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image = QImage(frame, frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)\n",
    "        self.procImg.setPixmap(QtGui.QPixmap.fromImage(image))\n",
    "        \n",
    "    def setSaveFolder(self):\n",
    "        self.saveFolder = QFileDialog.getExistingDirectory()\n",
    "        print('Image saved in: {0}'.format(self.saveFolder))\n",
    "        \n",
    "    def firstProbValue(self, value):\n",
    "        self.fstProbability = value\n",
    "        print('First cascade probability: ',value)\n",
    "        self.update()\n",
    "        \n",
    "    def secondProbValue(self, value):\n",
    "        self.secProbability = value\n",
    "        print('Second cascade probability: ',value)\n",
    "        self.update()\n",
    "    \n",
    "    def update(self):\n",
    "        self.label.setText(\"First cascade: {0}\".format(self.fstProbability))\n",
    "        self.label_2.setText(\"Second cascade: {0}\".format(self.secProbability))\n",
    "        if self.workStatus == True:\n",
    "            self.detectionModel.fstProb = self.fstProbability \n",
    "            self.detectionModel.secProb = self.secProbability\n",
    "        #self.setProcFrame(img)\n",
    "        #self.setOrigFrame(img2)\n",
    "        pass\n",
    "    \n",
    "    def multiStack(self, imgArray):\n",
    "        rows =  math.ceil(len(imgArray) ** 0.5)\n",
    "        delta = rows * rows - len(imgArray)\n",
    "        print(\"{0} of {1} used\".format(len(imgArray), rows))\n",
    "        imgStack = []\n",
    "\n",
    "        if isinstance(imgArray, list):\n",
    "            if len(imgArray) == 0:\n",
    "                gray_level = 127\n",
    "                gray_image = gray_level * np.ones((self.outputResolution[0], self.outputResolution[1], 3), dtype = np.uint8)\n",
    "                return gray_image\n",
    "            for x in range(0, rows):\n",
    "                result = []\n",
    "                for y in range(0, rows):\n",
    "                    if x * rows + y < len(imgArray):\n",
    "                        resized = cv.resize(imgArray[x * rows + y], \n",
    "                                            (round(self.outputResolution[0]/rows),round(self.outputResolution[1]/rows)))\n",
    "                        result.append(resized)\n",
    "                    else:\n",
    "                        gray_level = 127\n",
    "                        gray_image = gray_level * np.ones((round(\n",
    "                            self.outputResolution[0]/rows),round(self.outputResolution[1]/rows),3), dtype = np.uint8)\n",
    "                        result.append(gray_image)\n",
    "                imgStack.append(np.hstack(result))\n",
    "            return np.vstack(imgStack)\n",
    "        else:\n",
    "            assert 'Wrong Image Array type in stacking function'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
